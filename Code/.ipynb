{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changes in appearances of words in speeches between parties and congresses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we detect changes between two corpus of speeches taken from congressional records. This example shows you how to:\n",
    "\n",
    "- Load, arrange, and clean the data\n",
    "- Compute p-values\n",
    "- Use HC to detect changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load speech data\n",
    "import pandas as pd\n",
    "import two_unit_test\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "raw_corpus = pd.read_csv(\"../Data/speech_w_data_example.csv\", encoding = 'latin1')\n",
    "headers = list(raw_corpus)\n",
    "# print(headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select two units from raw corpus for comparison\n",
    "unit1 = raw_corpus.loc[(raw_corpus.party == 'R') & (raw_corpus.chamber == 'H') & (raw_corpus.congress_id == 114), ['speech_id', 'speech']]\n",
    "unit2 = raw_corpus.loc[(raw_corpus.party == 'D') & (raw_corpus.chamber == 'H') & (raw_corpus.congress_id == 114), ['speech_id', 'speech']]\n",
    "# print(list(unit1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_words = pd.read_csv(\"../Data/list_of_1500words.csv\", encoding = 'latin1', names = ['i','word']).iloc[:,1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc, features = two_unit_test.two_unit_test(unit1,unit2, list_of_words=list_of_words['word'][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import scipy.stats as stats\n",
    "from HC_aux import hc_vals\n",
    "\n",
    "#Some helper functions for two_unit_test function\n",
    "\n",
    "def get_z_score(freq_x,freq_y,total_x,total_y):\n",
    "    p = (freq_x + freq_y)/np.float((total_x + total_y))\n",
    "    se = np.sqrt(p * (1.0-p) * (1.0/total_x + 1.0/total_y))\n",
    "    z_score = (freq_x /np.float(total_x) - freq_y/np.float(total_y))/np.float(se)\n",
    "    return z_score\n",
    "\n",
    "def get_pval(z_score):\n",
    "    pval = 2 * stats.norm.cdf(-np.abs(z_score))\n",
    "    return pval\n",
    "\n",
    "def get_pval2(freq_x, freq_y,total_x,total_y):\n",
    "    pval2 = stats.binom_test(x = freq_x, n = freq_x + freq_y, \n",
    "                                  p = (total_x - freq_x) / np.float((total_y + total_x - freq_x - freq_y)))\n",
    "    return pval2\n",
    "\n",
    "\n",
    "import re\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import SnowballStemmer \n",
    "class LemmaTokenizer(object):\n",
    "     def __init__(self):\n",
    "         self.wnl = SnowballStemmer(language = 'english')\n",
    "     def __call__(self, doc):\n",
    "        doc = re.sub(r'[^A-Za-z0-9\\s]',r' ',doc)\n",
    "        doc = re.sub(r'\\n',r' ',doc)\n",
    "        doc = re.sub(r'[0-9]',r' ',doc)\n",
    "        #doc = re.sub(r'[a-z]\\040' ,r'',doc) #remove singletons\n",
    "        return [self.wnl.stem(t) for t in word_tokenize(doc)]\n",
    "\n",
    "\n",
    "# Input: unit1, unit2, which are dataframes with columns: speech_id (integer) , speech (string)\n",
    "# Input: context_words, non_context_words; these lists of words we will keep\n",
    "# Output: a dataframe containing hc statistic, a boolean array features which is 1 if the feature was important,\n",
    "#         and an array of corresponding words which were used for the HC evaluation\n",
    "\n",
    "def two_unit_test(unit1,unit2, list_of_words):\n",
    "    \n",
    "    #Operations on unit1\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "    import pandas as pd\n",
    "\n",
    "    tf_vectorizer = CountVectorizer(tokenizer=LemmaTokenizer(), vocabulary=list_of_words)\n",
    "    tf1 = tf_vectorizer.fit_transform(unit1['speech'])\n",
    "    tf2 = tf_vectorizer.fit_transform(unit2['speech'])\n",
    "  \n",
    "    word_counts = pd.DataFrame()\n",
    "    word_counts['word'] = (tf_vectorizer.get_feature_names())\n",
    "    word_counts['n1'] = np.array(tf1.sum(0)).T\n",
    "    word_counts['n2'] = np.array(tf2.sum(0)).T\n",
    "    word_counts['T1'] = word_counts['n1'].sum()\n",
    "    word_counts['T2'] = word_counts['n2'].sum()\n",
    "    \n",
    "    #Joining unit1 and unit2 for the HC computation\n",
    "    word_counts = word_counts[word_counts['n1'] + word_counts['n2'] >= 10] \n",
    "    word_counts['pval'] = word_counts.apply(lambda row: get_pval2(row['n1'], \n",
    "                                                         row['n2'], \n",
    "                                                         row['T1'],\n",
    "                                                        row['T2']), axis=1)\n",
    "    \n",
    "    #Pass in pval2, from binomial test, into HC function\n",
    "    hc_result = hc_vals(word_counts['pval'], alpha = 0.4)\n",
    "    features = hc_result.p_sorted_idx[:hc_result.i_max_star]\n",
    "    return hc_result.hc, features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HC score = 31.602752245928766\n",
      "List of distinguishing words:\n",
      "            word\n",
      "33        health\n",
      "138          pay\n",
      "101        chang\n",
      "1097       sound\n",
      "21           act\n",
      "32          hous\n",
      "745        earli\n",
      "634      opposit\n",
      "1336       prior\n",
      "420      generat\n",
      "7           work\n",
      "0              0\n",
      "1154     qualifi\n",
      "1028          ii\n",
      "49          rule\n",
      "275         oper\n",
      "507      thought\n",
      "1498           n\n",
      "84        public\n",
      "264       propos\n",
      "38         feder\n",
      "358         texa\n",
      "75        school\n",
      "1151        ship\n",
      "1378     counsel\n",
      "911         type\n",
      "11          time\n",
      "153     appropri\n",
      "867        river\n",
      "241       effect\n",
      "...          ...\n",
      "445       review\n",
      "1394        deep\n",
      "1491      fourth\n",
      "1027     consist\n",
      "813         rest\n",
      "446     unfortun\n",
      "660       sector\n",
      "448          isi\n",
      "1122      broken\n",
      "1392    unemploy\n",
      "1367        firm\n",
      "1240   certainti\n",
      "756      conduct\n",
      "1268       april\n",
      "736         ohio\n",
      "233        stand\n",
      "10            mr\n",
      "1382       ocean\n",
      "252       commit\n",
      "1135        isil\n",
      "400         fail\n",
      "163       number\n",
      "1290    civilian\n",
      "120         week\n",
      "651   regulatori\n",
      "782       religi\n",
      "220       immigr\n",
      "1167      realiz\n",
      "910         knew\n",
      "338         aisl\n",
      "\n",
      "[599 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"HC score = {}\".format(hc))\n",
    "\n",
    "print(\"List of distinguishing words:\")\n",
    "# Which words cause the difference?\n",
    "print(list_of_words.reindex(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
